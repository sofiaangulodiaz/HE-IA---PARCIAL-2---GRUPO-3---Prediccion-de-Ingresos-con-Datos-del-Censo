# ðŸ“Š PredicciÃ³n de Ingresos con Datos del Censo

Proyecto de IA aplicada con **PyTorch** para predecir si una persona gana mÃ¡s de **$50K anuales** usando el dataset **Adult Census (UCI, 1994)**.

Incluye:
- Exploratory Data Analysis (EDA)
- Preprocesamiento de datos (imputaciÃ³n, escalado, one-hot)
- RegresiÃ³n LogÃ­stica como modelo baseline
- Redes Neuronales (MLP)
- TÃ©cnicas de regularizaciÃ³n: **Dropout**, **BatchNorm**, **EarlyStopping**, **weight decay** y **gradient clipping**

Se comparan modelos y mÃ©tricas en **entrenamiento**, **validaciÃ³n** y **prueba**, destacando la importancia del preprocesamiento y la regularizaciÃ³n en el desempeÃ±o final.

## ðŸ‘©â€ðŸ’» Proyecto desarrollado como parte del curso HE2 - Inteligencia Artificial Aplicada

## ðŸ‘©â€ðŸ’» Autores
- SofÃ­a Angulo
- Juan Felipe Benites

---

## ðŸ“‚ Estructura del Repositorio
â”œâ”€â”€ parcial2.ipynb                # Notebook principal (pipeline completo)    
â”œâ”€â”€ Reporte                      # Informe (secciones 1â€“4) y anexos  
â””â”€â”€ README.md                     # Este archivo

---

## ðŸ§­ Resumen ejecutivo
- **Splits:** TRAIN **32,561**, VALIDACIÃ“N **8,140**, PRUEBA **8,141** (estratificados)
- **Clases:** ~**76%** (â‰¤$50K) / **24%** (>$50K) estables en los 3 conjuntos
- **Features finales:** **100** columnas tras One-Hot Encoding (OHE)

### Resultados clave 
**RegresiÃ³n LogÃ­stica** (umbral optimizado en validaciÃ³n **t\*=0.53**):  
- TRAIN â†’ Loss **0.5789**, Acc **0.8190**, Prec **0.5886**, Rec **0.8249**, F1 **0.6870**, AUC **0.9070**  
- VALIDACIÃ“N â†’ Loss **0.5987**, Acc **0.8117**, Prec **0.5711**, Rec **0.8144**, F1 **0.6714**, AUC **0.8984**  
- PRUEBA â†’ Loss **0.5654**, Acc **0.8216**, Prec **0.5876**, Rec **0.8216**, F1 **0.6852**, AUC **0.9106**

**MLP con regularizaciÃ³n (mejor experimento)**  
Arquitectura **(128, 64)** + **BatchNorm** + **Dropout=0.2**, **AdamW lr=1e-3**, **weight_decay=1e-4**, **BCEWithLogitsLoss**, **EarlyStopping=6**, **batch=128**  
- VALIDACIÃ“N â†’ **ValLossâ‰ˆ0.576** (rango 0.576â€“0.582), **ValAcc picoâ‰ˆ0.809**  


**ConclusiÃ³n rÃ¡pida:** el baseline lineal ya logra **AUCâ‰ˆ0.91** y **F1â‰ˆ0.685** en PRUEBA. El MLP **sin** regularizaciÃ³n sobreajusta; **con** regularizaciÃ³n se estabiliza y **se acerca** al baseline, sin superarlo con la evidencia actual.

---

## ðŸ”¬ Datos y preprocesamiento
- **Variables:** 14 columnas originales (numÃ©ricas y categÃ³ricas)
- **ImputaciÃ³n:** mediana (numÃ©ricas) y moda (categÃ³ricas), **fit solo en TRAIN**
- **Escalado:** **StandardScaler** en numÃ©ricas (**fit en TRAIN**)
- **CodificaciÃ³n:** **One-Hot** con `drop='first'` y `handle_unknown='ignore'`
- **DimensiÃ³n final:** **100** features
- **Loaders:** `batch=128`, `shuffle=True` solo en TRAIN
- **Evitar fuga de informaciÃ³n:** todas las estadÃ­sticas (imputaciÃ³n, escalado, OHE) se ajustan **exclusivamente con TRAIN** y se aplican a VAL/TEST

**Figuras sugeridas (tÃ­tulos exactos del notebook/PDF):**
- `income (TRAIN)`, `income (VAL)`, `income (TEST)`
- `Histogramas numÃ©ricas (TRAIN)`
- `DistribuciÃ³n de occupation (TOP 15, TRAIN)` (u otra categÃ³rica clave)
- `hours-per-week segÃºn income (TRAIN)`

---

## ðŸ§  Modelos

### Baseline â€” RegresiÃ³n LogÃ­stica
- Entrenada sobre 100 features (post-OHE)
- SelecciÃ³n de **umbral t\*** en VALIDACIÃ“N (max **F1**, t\*â‰ˆ**0.53**)
- MÃ©tricas completas en TRAIN/VALIDACIÃ“N/PRUEBA (ver â€œResultados claveâ€)

### MLP â€” sin vs. con regularizaciÃ³n
- **Sin regularizaciÃ³n:** sobreajuste (TrainAcc >0.90; ValAcc ~0.80â€“0.82; ValLoss creciente)
- **Con regularizaciÃ³n (mejor experimento):**
  - Arquitectura **(128, 64)**, **BatchNorm**, **Dropout=0.2**
  - **AdamW** (lr=1e-3, wd=1e-4), **BCEWithLogitsLoss**
  - **Gradient clipping** y **EarlyStopping=6**
  - VALIDACIÃ“N: **ValLossâ‰ˆ0.576**, **ValAcc picoâ‰ˆ0.809**

**Figuras de entrenamiento (tÃ­tulos exactos):**  
`NoReg Run <ID> - PÃ©rdida vs Ã‰pocas` Â· `NoReg Run <ID> - Accuracy vs Ã‰pocas` Â· `Run <ID> - PÃ©rdida vs Ã‰pocas (con EarlyStopping)`



---

## â–¶ï¸ CÃ³mo reproducir
1. **Instalar**  
   ```bash
   # Python >= 3.10
   pip install torch scikit-learn pandas numpy matplotlib


